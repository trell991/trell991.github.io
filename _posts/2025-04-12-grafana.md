---
title: "Dashboard as Code: Import Grafana Dashboards with Python ðŸ "
date: 2025-04-12 8:00:00 +0000
categories: [Personal Projects]
tags: [Python,Grafana,Prometheus,Node Exporter]
layout: post
---

I wanted to share a nifty Python script I wrote that automatically imports the Grafana dashboard **1860** for quick setup.

Why would you want to do this? Honestly, I donâ€™t know â€” but the reason *I* did it is because itâ€™s part of a larger project Iâ€™m working on called **Chaos Labs** (more on that in a future post).

So for my project **Chaos Labs**, I built Ubuntu image with a simple monitoring stack pre-installed: Prometheus, Node Exporter, and Grafana. The image was built with Packer. I wanted everything â€” including the monitoring stack â€” to be fully configured and baked into the image.

Why? Because setting up monitoring can be time-consuming, and I wanted people to be able to quickly deploy this image using Terraform, test their applications, and have monitoring ready to go out of the box. Whether theyâ€™re stress testing an app or just playing around on the Ubuntu image, the idea was to make setup seamless.

Plus, this was a fun way for me to practice some automation skills. ðŸ˜Ž

I originally tried to write this script in Bash, but it got a little too complicated. I didnâ€™t realize how many steps you have to jump through to import a dashboard with the Grafana API. I decided to go with python and use the **requests** library. So off I went, diving into the official Grafana API docs.

After wasting a few hours unknowingly using **deprecated** Grafana HTTP APIs ðŸ˜­, I finally figured out the necessary API call sequencing to get what I needed. While I thought this would be a quick one-and-done, it ended up taking quite some time and about 150 lines of code â€” but it was worth it!

## Prerequisites

- An ubuntu server with Prometheus, Grafana, and Node exporter installed & running
- All services running on defaults ports Grafana 3000, Prometheus, Node exporter

## So lets break it down ðŸ•ºðŸ¾

First lets go through the API sequencing steps

1. Create a Grafana service account
2. Create a Grafana service account token
3. Add Node Exporter as a dashboard
4. Download the json for the Grafana Dashboard (1860)
5. Import the downloaded Dashboard

Not too bad right ?

## Lets break down the code

> Not for production use.
{: .prompt-warning }

Here Iâ€™m importing the necessary libraries and Base64-encoding the default Grafana credentials so I can create a service account.

```python
#!/usr/bin/env python3
# Written by: Tai H.

import requests
import base64
import json

# Setting credentials
username = 'admin'
password = 'admin'
grafana_creds = f'{username}:{password}'

# Base64 encoding credentials
encoded_grafana_creds = base64.b64encode(
    grafana_creds.encode('utf-8')).decode('utf-8')
```

> Next, Iâ€™m getting the public IP address of my server since Grafana is running on it. I'm using ipinfo.io for this. The response gives me the IP, which Iâ€™ll need for building my HTTP requests.

```python
# Get the public IP address using ipinfo.io
ipinfo_response = requests.get('https://ipinfo.io/ip')

# response.text gives the plain IP without JSON structure
host_ip = ipinfo_response.text.strip()
```

> Here I create a service account with the hardcoded name "test-service-account". I build the request URL using host_ip and port 3000. The status code for a successful request is 201, so I added basic error handling. I also capture the service account ID for the next step.

```python
# Create Grafana Service Account
url = f'http://{host_ip}:3000/api/serviceaccounts'
service_acct_headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Basic {encoded_grafana_creds}',
}
service_acct_data = {
    'name': 'test-service-account',
    'role': 'Admin',
    'isDisabled': False
}

service_acct_response = requests.post(
    url, headers=service_acct_headers, json=service_acct_data)

# Error handling for service account creation
if service_acct_response.status_code == 201:
    data = service_acct_response.json()
    id = data.get('id')
    name = data.get('name')
    print(f'"{name}" was successfully created')
else:
    print('Failed to create the service account')
    print(f'Status Code: {service_acct_response.text}')
```

> The process is similar here. This time, I pass in the service account ID to generate a token. I set secondsToLive to 0 so the token never expires (not recommended for production).

```python
# Create Service account token
service_acct_url = f'http://{host_ip}:3000/api/serviceaccounts/{id}/tokens'
service_acct_headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Basic {encoded_grafana_creds}',
}
service_acct_token = {
    'name': 'test-service-account',
    'secondsToLive': 0
}

service_acct_token_response = requests.post(
    service_acct_url, headers=service_acct_headers, json=service_acct_token)

# Error handling for service account toke creation 
if service_acct_token_response.status_code == 200:
    token_data = service_acct_token_response.json()
    key = token_data.get('key')
    print(f'Token is: {key}')
else:
    print('Failed to create the service account token')
    print(f'{service_acct_token_response.text}')
```

> Now Iâ€™m adding Node Exporter as a data source. The authorization header uses the service account token, and I hardcoded the name as "Prometheus." The URL points to the Prometheus server, which is also running on the same machine.

```python
# Add Node Exporter Data Source
add_data_source_url = f'http://{host_ip}:3000/api/datasources'

add_data_source_headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {key}',
}

add_data_source_body = {
    'name': 'Prometheus',
    'type': 'prometheus',
    'url': f'http://{host_ip}:9090',
    'access': 'proxy',
    'basicAuth': False
}

add_data_source_response = requests.post(
    add_data_source_url, headers=add_data_source_headers, json=add_data_source_body)

if add_data_source_response.status_code == 200:
    data_source_json = add_data_source_response.json()
    data_source_name = data_source_json.get('name')
    print(f'Successfully added: {name} as a Datasource')
else:
    print('Failed to add Node exporter as a data source')
    print(f'{add_data_source_response.text}')
```

> Now that node Exporter is imported as a datasource, we can download a dashboard from the [Grafana Dashboard Gallery](https://grafana.com/grafana/dashboards/) Im using [dashboard 1860](https://grafana.com/grafana/dashboards/1860-node-exporter-full/). In this snippet im downloading dashboard 1860 and writing the json to the file grafana_dashboard_response.text

```python
# Downloading the json for Grafana Dashboard (1860) this is a node exporter dashboard
grafana_dashboard_url = "https://grafana.com/api/dashboards/1860/revisions/latest/download"
grafana_dashboard_response = requests.get(grafana_dashboard_url)

if grafana_dashboard_response.status_code == 200:
    with open('dashboard_1860.json', 'w') as file:
        file.write(grafana_dashboard_response.text)
    print('successfully downloaded Grafana dashboard:1860')
else:
    print(
        f'Failed to download Grafana dashboard: 1860 with status code: {grafana_dashboard.status_code}')
    print(grafana_dashboard_response.text)
    exit(1)
```

> Before importing, I clean up the JSON: clear the id, uid, and tags, and set a custom title.

```python
# Import the downloaded dashboard (1860)
with open('dashboard_1860.json', 'r') as file:
    dashboard_1860 = json.load(file)

# Setting these properties to none for a clean import 
dashboard_1860["id"] = None
dashboard_1860["uid"] = None
dashboard_1860["tags"] = None
dashboard_1860["title"] = 'Prometheus Dash'
```

> Finally, I import the cleaned dashboard using the Grafana API.

```python
dashboard_url = f'http://{host_ip}:3000/api/dashboards/db'
dashboard_headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {key}',
}

dashboard_body = {
    'dashboard': dashboard_1860,
    'folderUid': None,
    'messsage': 'Imported via api',
    'overwrite': False
}

dashboard_response = requests.post(
    dashboard_url, headers=dashboard_headers, json=dashboard_body)

# Error handling for dashboard (1860) import
if dashboard_response.status_code == 200:
    dashboard_data = dashboard_response.json()
    dashboard_title = dashboard_data.get('slug')
    print(f'Successfully created dashboard: {dashboard_title}')
else:
    print('Failed to import the dashboard')
    print(f'Error: {dashboard_response.text}')
```
