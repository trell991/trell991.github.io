---
title: "Dashboard as Code: Import Grafana Dashboards with Python 🐍 "
date: 2025-04-12 8:00:00 +0000
categories: [Personal Projects]
tags: [Python,Grafana,Prometheus,Node Exporter]
layout: post
---

I wanted to share a nifty Python script I wrote that automatically imports the Grafana dashboard **1860** for quick setup.

Why would you want to do this? Honestly, I don’t know — but the reason *I* did it is because it’s part of a larger project I’m working on called **Chaos Labs** (more on that in a future post).

So for my project **Chaos Labs**, I built Ubuntu image with a simple monitoring stack pre-installed: Prometheus, Node Exporter, and Grafana. The image was built with Packer. I wanted everything — including the monitoring stack — to be fully configured and baked into the image.

Why? Because setting up monitoring can be time-consuming, and I wanted people to be able to quickly deploy this image using Terraform, test their applications, and have monitoring ready to go out of the box. Whether they’re stress testing an app or just playing around on the Ubuntu image, the idea was to make setup seamless.

Plus, this was a fun way for me to practice some automation skills. 😎

I originally tried to write this script in Bash, but it got a little too complicated. I didn’t realize how many steps you have to jump through to import a dashboard with the Grafana API. I decided to go with python and use the **requests** library. So off I went, diving into the official Grafana API docs.

After wasting a few hours unknowingly using **deprecated** Grafana HTTP APIs 😭, I finally figured out the necessary API call sequencing to get what I needed. While I thought this would be a quick one-and-done, it ended up taking quite some time and about 150 lines of code — but it was worth it!

## Prerequisites

- An ubuntu server with Prometheus, Grafana, and Node exporter installed & running
- All services running on defaults ports Grafana 3000, Prometheus, Node exporter

## So lets break it down 🕺🏾

First lets go through the API sequencing steps

1. Create a Grafana service account
2. Create a Grafana service account token
3. Add Node Exporter as a dashboard
4. Download the json for the Grafana Dashboard (1860)
5. Import the downloaded Dashboard

Not too bad right ?

## Lets break down the code

> Not for production use.
{: .prompt-warning }

Here I’m importing the necessary libraries and Base64-encoding the default Grafana credentials so I can create a service account.

```python
#!/usr/bin/env python3
# Written by: Tai H.

import requests
import base64
import json

# Setting credentials
username = 'admin'
password = 'admin'
grafana_creds = f'{username}:{password}'

# Base64 encoding credentials
encoded_grafana_creds = base64.b64encode(
    grafana_creds.encode('utf-8')).decode('utf-8')
```

> Next, I’m getting the public IP address of my server since Grafana is running on it. I'm using ipinfo.io for this. The response gives me the IP, which I’ll need for building my HTTP requests.

```python
# Get the public IP address using ipinfo.io
ipinfo_response = requests.get('https://ipinfo.io/ip')

# response.text gives the plain IP without JSON structure
host_ip = ipinfo_response.text.strip()
```

> Here I create a service account with the hardcoded name "test-service-account". I build the request URL using host_ip and port 3000. The status code for a successful request is 201, so I added basic error handling. I also capture the service account ID for the next step.

```python
# Create Grafana Service Account
url = f'http://{host_ip}:3000/api/serviceaccounts'
service_acct_headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Basic {encoded_grafana_creds}',
}
service_acct_data = {
    'name': 'test-service-account',
    'role': 'Admin',
    'isDisabled': False
}

service_acct_response = requests.post(
    url, headers=service_acct_headers, json=service_acct_data)

# Error handling for service account creation
if service_acct_response.status_code == 201:
    data = service_acct_response.json()
    id = data.get('id')
    name = data.get('name')
    print(f'"{name}" was successfully created')
else:
    print('Failed to create the service account')
    print(f'Status Code: {service_acct_response.text}')
```

> The process is similar here. This time, I pass in the service account ID to generate a token. I set secondsToLive to 0 so the token never expires (not recommended for production).

```python
# Create Service account token
service_acct_url = f'http://{host_ip}:3000/api/serviceaccounts/{id}/tokens'
service_acct_headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Basic {encoded_grafana_creds}',
}
service_acct_token = {
    'name': 'test-service-account',
    'secondsToLive': 0
}

service_acct_token_response = requests.post(
    service_acct_url, headers=service_acct_headers, json=service_acct_token)

# Error handling for service account toke creation 
if service_acct_token_response.status_code == 200:
    token_data = service_acct_token_response.json()
    key = token_data.get('key')
    print(f'Token is: {key}')
else:
    print('Failed to create the service account token')
    print(f'{service_acct_token_response.text}')
```

> Now I’m adding Node Exporter as a data source. The authorization header uses the service account token, and I hardcoded the name as "Prometheus." The URL points to the Prometheus server, which is also running on the same machine.

```python
# Add Node Exporter Data Source
add_data_source_url = f'http://{host_ip}:3000/api/datasources'

add_data_source_headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {key}',
}

add_data_source_body = {
    'name': 'Prometheus',
    'type': 'prometheus',
    'url': f'http://{host_ip}:9090',
    'access': 'proxy',
    'basicAuth': False
}

add_data_source_response = requests.post(
    add_data_source_url, headers=add_data_source_headers, json=add_data_source_body)

if add_data_source_response.status_code == 200:
    data_source_json = add_data_source_response.json()
    data_source_name = data_source_json.get('name')
    print(f'Successfully added: {name} as a Datasource')
else:
    print('Failed to add Node exporter as a data source')
    print(f'{add_data_source_response.text}')
```

> Now that node Exporter is imported as a datasource, we can download a dashboard from the [Grafana Dashboard Gallery](https://grafana.com/grafana/dashboards/) Im using [dashboard 1860](https://grafana.com/grafana/dashboards/1860-node-exporter-full/). In this snippet im downloading dashboard 1860 and writing the json to the file grafana_dashboard_response.text

```python
# Downloading the json for Grafana Dashboard (1860) this is a node exporter dashboard
grafana_dashboard_url = "https://grafana.com/api/dashboards/1860/revisions/latest/download"
grafana_dashboard_response = requests.get(grafana_dashboard_url)

if grafana_dashboard_response.status_code == 200:
    with open('dashboard_1860.json', 'w') as file:
        file.write(grafana_dashboard_response.text)
    print('successfully downloaded Grafana dashboard:1860')
else:
    print(
        f'Failed to download Grafana dashboard: 1860 with status code: {grafana_dashboard.status_code}')
    print(grafana_dashboard_response.text)
    exit(1)
```

> Before importing, I clean up the JSON: clear the id, uid, and tags, and set a custom title.

```python
# Import the downloaded dashboard (1860)
with open('dashboard_1860.json', 'r') as file:
    dashboard_1860 = json.load(file)

# Setting these properties to none for a clean import 
dashboard_1860["id"] = None
dashboard_1860["uid"] = None
dashboard_1860["tags"] = None
dashboard_1860["title"] = 'Prometheus Dash'
```

> Finally, I import the cleaned dashboard using the Grafana API.

```python
dashboard_url = f'http://{host_ip}:3000/api/dashboards/db'
dashboard_headers = {
    'Content-Type': 'application/json',
    'Authorization': f'Bearer {key}',
}

dashboard_body = {
    'dashboard': dashboard_1860,
    'folderUid': None,
    'messsage': 'Imported via api',
    'overwrite': False
}

dashboard_response = requests.post(
    dashboard_url, headers=dashboard_headers, json=dashboard_body)

# Error handling for dashboard (1860) import
if dashboard_response.status_code == 200:
    dashboard_data = dashboard_response.json()
    dashboard_title = dashboard_data.get('slug')
    print(f'Successfully created dashboard: {dashboard_title}')
else:
    print('Failed to import the dashboard')
    print(f'Error: {dashboard_response.text}')
```
